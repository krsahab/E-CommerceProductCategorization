{"nbformat":4,"nbformat_minor":2,"metadata":{"orig_nbformat":4,"language_info":{"name":"python","version":"3.9.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3.9.6 64-bit"},"interpreter":{"hash":"ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"},"colab":{"name":"Amazon2.ipynb","provenance":[]}},"cells":[{"cell_type":"code","execution_count":null,"source":["import gc\r\n","import csv\r\n","import nltk\r\n","import pickle\r\n","import pandas as pd\r\n","import contractions\r\n","import unidecode\r\n","from nltk.corpus import stopwords\r\n","from nltk.tokenize import word_tokenize\r\n","from nltk.stem import WordNetLemmatizer\r\n","from sklearn.feature_extraction.text import CountVectorizer\r\n","from sklearn.preprocessing import LabelBinarizer"],"outputs":[],"metadata":{"id":"ehAmwPCWxnj5"}},{"cell_type":"code","execution_count":null,"source":["nltk.download('punkt')\r\n","nltk.download('stopwords')\r\n","nltk.download('wordnet')\r\n","stop = stopwords.words('english')\r\n","wordnet_lemmatizer = WordNetLemmatizer()\r\n","label_binarizer = LabelBinarizer()\r\n","count_vectorizer = CountVectorizer(tokenizer=lambda doc: doc, lowercase=False)"],"outputs":[],"metadata":{"id":"n2jTN9uDxnj5"}},{"cell_type":"code","execution_count":null,"source":["def lemmatize_text(text):\r\n","    return [wordnet_lemmatizer.lemmatize(w) for w in text]"],"outputs":[],"metadata":{"id":"Pew9dcZ4xnj6"}},{"cell_type":"code","execution_count":null,"source":["def standardize_text(df, column):\r\n","    df[column] = df[column].str.replace(r\"[^A-Za-z]\", \" \")\r\n","    df[column] = df[column].str.lower()\r\n","    df[column] = df[column].apply(contractions.fix)\r\n","    df[column] = df[column].apply(word_tokenize)\r\n","    df[column] = df[column].apply(lemmatize_text)\r\n","    df[column] = df[column].apply(lambda x: [item for item in x if len(item)>2 and item not in stop])\r\n","    return df"],"outputs":[],"metadata":{"id":"SOF_7NGyxnj6"}},{"cell_type":"code","execution_count":null,"source":["def standardize_brand(df, column):\r\n","    df[column] = df[column].apply(unidecode.unidecode)\r\n","    df[column] = df[column].str.replace(r\"[^A-Za-z0-9]\", \"\")\r\n","    df[column] = df[column].str.lower()\r\n","    return df"],"outputs":[],"metadata":{"id":"AyH45jCgxnj7"}},{"cell_type":"code","execution_count":null,"source":["def merge(row):\r\n","    res = list(set().union(row['TITLE'], row['DESCRIPTION'], row['BULLET_POINTS']))\r\n","    res.append(row['BRAND'])\r\n","    return res"],"outputs":[],"metadata":{"id":"HNCfEr2Axnj7"}},{"cell_type":"code","execution_count":null,"source":["def data_clean(data):\r\n","    for column in data.columns:\r\n","        if column == 'BRAND':\r\n","            data = standardize_brand(data, column)\r\n","        else:\r\n","            data = standardize_text(data, column)    \r\n","    data['FEATURE'] = data.apply(merge, axis=1)\r\n","    data = data.drop(columns=['TITLE', 'DESCRIPTION', 'BULLET_POINTS', 'BRAND'])\r\n","    return data['FEATURE'].values"],"outputs":[],"metadata":{"id":"kL9Jio8Exnj8"}},{"cell_type":"markdown","source":["Process Train Data"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["data = pd.read_csv(\"/content/gdrive/MyDrive/Contest/dataset/train.csv\", escapechar = \"\\\\\", quoting = csv.QUOTE_NONE, error_bad_lines=False, na_filter=False)\r\n","label = data['BROWSE_NODE_ID'].values\r\n","data = data.drop(columns='BROWSE_NODE_ID')"],"outputs":[],"metadata":{"id":"TE51CQn-xnj8"}},{"cell_type":"markdown","source":["Process data in chunks as it is too big to be processed in one go because on RAM/Memory/Resource constraints, and the same can be applied while working on data.\r\n","It also minimizes the effort and time loss in case of failure.\r\n","This can also be done while reading the data itselt, by providing the nrows and skiprows parameters in read_csv function."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["for i in range(15):\r\n","  s = i*200000\r\n","  e = min(s+200000, data.shape[0])\r\n","  data_cleaned = data_clean(data[s:e])\r\n","  label_temp = label[s:e]\r\n","  data_temp = pd.DataFrame({'FEATURE':data_cleaned, 'BROWSE_NODE_ID':label_temp})\r\n","  data_temp = data_temp[['FEATURE', 'BROWSE_NODE_ID']]\r\n","  file_name = 'data'+str(i)+'.pkl'\r\n","  data_temp.to_pickle(file_name)\r\n","  del data_cleaned\r\n","  del label_temp\r\n","  del data_temp\r\n","  gc.collect()"],"outputs":[],"metadata":{"id":"4KeuhNeseGJ_"}},{"cell_type":"markdown","source":["Create small dataset with n rows of each label/class"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["n = 5\r\n","classes = {}\r\n","final_data = []\r\n","final_label = []\r\n","path = '/content/gdrive/MyDrive/Contest/'"],"outputs":[],"metadata":{"id":"3Hu7gTjYCVdL","executionInfo":{"status":"ok","timestamp":1627813933836,"user_tz":-330,"elapsed":3846,"user":{"displayName":"Kumar Sahab","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghzxml3qIDA8AdGxv3OosA8WCxMhIFNRpcm14KokQ=s64","userId":"04630224057934138359"}}}},{"cell_type":"code","execution_count":null,"source":["for i in range(15):\r\n","  file_name = 'data'+str(i)+'.pkl'\r\n","  print(path+file_name)\r\n","  data = pd.read_pickle(path+file_name)\r\n","  for rows in data.values:\r\n","    if rows[1] not in classes:\r\n","      classes[rows[1]] = 1\r\n","      final_data.append(rows[0])\r\n","      final_label.append(rows[1])\r\n","    elif classes[rows[1]]<n:\r\n","      classes[rows[1]] += 1\r\n","      final_data.append(rows[0])\r\n","      final_label.append(rows[1])\r\n","  del data\r\n","  gc.collect()"],"outputs":[],"metadata":{"id":"r_CrO1AZF0Nr"}},{"cell_type":"code","execution_count":null,"source":["data_processed = pd.DataFrame({'FEATURE':final_data, 'LABEL':final_label})\r\n","data_processed = data_processed[['FEATURE', 'LABEL']]\r\n","data_processed.to_pickle('data_processed_lite.pkl')"],"outputs":[],"metadata":{"id":"bbCOqlcLILGq","executionInfo":{"status":"ok","timestamp":1627814016889,"user_tz":-330,"elapsed":2393,"user":{"displayName":"Kumar Sahab","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghzxml3qIDA8AdGxv3OosA8WCxMhIFNRpcm14KokQ=s64","userId":"04630224057934138359"}}}},{"cell_type":"markdown","source":["Process test data"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["data = pd.read_csv(\"/content/gdrive/MyDrive/Contest/dataset/test.csv\", escapechar = \"\\\\\", quoting = csv.QUOTE_NONE, error_bad_lines=False, na_filter=False)\r\n","ID = data['PRODUCT_ID'].values\r\n","data = data.drop(columns='PRODUCT_ID')"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["data_cleaned = data_clean(data)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["pickle.dump(ID, open(\"ID_test_pickle\",\"wb\"))\r\n","pickle.dump(data_cleaned, open(\"data_test_pickle\",\"wb\"))"],"outputs":[],"metadata":{}}]}