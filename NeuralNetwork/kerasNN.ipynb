{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pickle\r\n",
    "import numpy as np\r\n",
    "import gc\r\n",
    "import pandas as pd\r\n",
    "from scipy import sparse\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import LabelBinarizer\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow import keras\r\n",
    "from tensorflow.keras import layers\r\n",
    "from keras.regularizers import L1L2\r\n",
    "import pickle\r\n",
    "import numpy as np\r\n",
    "import gc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "One Time Processing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "label_binarizer = LabelBinarizer()\r\n",
    "count_vectorizer = CountVectorizer(tokenizer=lambda doc: doc, lowercase=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = pd.read_pickle('/content/gdrive/MyDrive/Data/dataset/data_processed_lite.pkl')\r\n",
    "data_cleaned = data['FEATURE'].values\r\n",
    "label = data['LABEL'].values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_cleaned = count_vectorizer.fit_transform(data_cleaned)\r\n",
    "label = label_binarizer.fit_transform(label)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sparse.save_npz(\"datanpz.npz\", data_cleaned)\r\n",
    "pickle.dump(label, open(\"label_csr.pkl\",\"wb\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training Starts Here"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_ratio=0.2\r\n",
    "random_st=40\r\n",
    "ep = 1\r\n",
    "lr = 0.01\r\n",
    "dropout = 0.5 #can be different for different layers\r\n",
    "batch = 128"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "your_matrix_back = sparse.load_npz(\"datanpz.npz\")\r\n",
    "csr_dict = pickle.load(open(\"label_csr.pkl\",\"rb\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_cleaned = your_matrix_back[0:5000].toarray()\r\n",
    "label = csr_dict[0:5000]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(data_cleaned, label, test_size=test_ratio, random_state=random_st)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Free RAM\r\n",
    "del data_cleaned\r\n",
    "del label\r\n",
    "gc.collect()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "output_class = Y_train.shape[-1]\r\n",
    "input_size = X_train.shape[-1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Sample Keras NN Model\r\n",
    "model = keras.Sequential([\r\n",
    "    keras.Input(shape=(input_size, )),\r\n",
    "    layers.Dense(4096, kernel_regularizer=L1L2(l1=0.0, l2=0.1), activation='relu'),\r\n",
    "    layers.BatchNormalization(),\r\n",
    "    layers.Dropout(dropout),\r\n",
    "    layers.Dense(4096, activation='relu'),\r\n",
    "    layers.BatchNormalization(),\r\n",
    "    layers.Dropout(dropout),\r\n",
    "    layers.Dense(output_class, activation='softmax')\r\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.compile(loss=keras.losses.CategoricalCrossentropy(), metrics=['accuracy'], optimizer=keras.optimizers.Adam(learning_rate=lr))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training in chunks, as entire data is too big to be loaded into the RAM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for j in range(ep):\r\n",
    "  for i in range(16):\r\n",
    "    s, e = i*3000, min(i*3000+3000, your_matrix_back.shape[0])\r\n",
    "    data_cleaned = your_matrix_back[s:e].toarray()\r\n",
    "    label = csr_dict[s:e]\r\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(data_cleaned, label, test_size=test_ratio, random_state=random_st)\r\n",
    "    model.fit(X_train, Y_train, batch_size=batch, epochs=ep, validation_data=(X_test, Y_test), shuffle = True)\r\n",
    "    del data_cleaned\r\n",
    "    del label\r\n",
    "    gc.collect()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.save(\"my_model\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = keras.models.load_model(\"my_model\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_data = pd.read_pickle('/content/gdrive/MyDrive/Data/dataset/data_test_pickle')\r\n",
    "ID = pd.read_pickle('/content/gdrive/MyDrive/Data/dataset/ID_test_pickle')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Predicting classes of test data in chunks, for same above reason"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "res = []\r\n",
    "for i in range(56):\r\n",
    "    print(i)\r\n",
    "    s, e = i*2000, min(test_data.shape[0], i*2000+2000)\r\n",
    "    temp = test_data[s:e]\r\n",
    "    temp = count_vectorizer.transform(temp.values)\r\n",
    "    temp = temp.toarray()\r\n",
    "    output = model.predict(temp)\r\n",
    "    output = label_binarizer.inverse_transform(output)\r\n",
    "    res.extend(output)\r\n",
    "    del temp\r\n",
    "    del output\r\n",
    "    gc.collect()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "submission = pd.DataFrame({'PRODUCT_ID':ID, 'BROWSE_NODE_ID':res})\r\n",
    "submission = submission[['PRODUCT_ID', 'BROWSE_NODE_ID']]\r\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}